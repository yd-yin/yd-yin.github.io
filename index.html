<!DOCTYPE HTML> 
<html lang="en" xmlns="http://www.w3.org/1999/html">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Yingda Yin</title>

  <meta name="author" content="Yingda Yin">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="css/stylesheet.css">
</head>

<body>
<table style="width: 100%; max-width: 920px; border: 0px; border-spacing: 0px; border-collapse: separate; margin-right: auto; margin-left: auto; ">
  <tbody>
  <tr style="padding: 0px">
    <td style="padding: 0px">

      <table style="width: 100%; border: 0px; border-spacing: 0px; border-collapse: separate; margin-right: auto; margin-left: auto; ">
        <tbody>
        <tr>
          <td style="padding: 20px; width: 66%; vertical-align: middle">
            <p style="text-align: center; font-family: Georgia, 'Lato', Verdana, Helvetica, sans-serif; font-size: 36px; line-height: 0; margin-top: 30px">
              Yingda Yin
            </p>
            <p style="text-align: center; font-family: serif, 'Lato', Verdana, Helvetica, sans-serif; font-size: 22px; line-height: 0.5; margin-bottom: 45px">
              尹英达
            </p>
            <p style="text-align: left; font-size: 17px;">
              <b> Ph.D. student </b> <br>
              School of Computer Science <br>
              Peking University <br>
            </p>
            <p style="text-align: left; font-size: 17px; margin-bottom: 1px">
              <b>Email</b>: yingda.yin at pku.edu.cn
            </p>
            <p style="text-align: left; text-indent: 50px; font-size: 17px; margin-top: 1px; margin-bottom: 0">
              yingda.yin at gmail.com
            </p>
          </td>

          <td style="padding: 2.5%; padding-right: 30px; ">
            <a href="images/portrait.jpg"><img style="width: 100%; max-width: 100%" alt="profile photo" src="images/portrait.jpg"
                                               class="hoverZoomLink"></a>
          </td>
        </tr>
        </tbody>
      </table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20" style="border-collapse: separate">
        <tbody>
        <tr>
          <td style="padding-top: 0; ">
            <p style="margin-top: 5px">
              <bio>
                I am a Ph.D. student at <a href="https://cs.pku.edu.cn/">School of Computer Science</a>, <a
                      href="https://www.pku.edu.cn/">Peking University</a>, where I am honored to be advised by <a href="https://cfcs.pku.edu.cn/baoquan/">Prof. Baoquan Chen</a>
                and co-advised by <a href="https://hughw19.github.io/">Prof. He Wang</a>.
                I am also fortunate to work closely with <a href="https://fqnchina.github.io/">Dr. Qingnan Fan</a> at Tencent AI Lab.
              </bio>
            </p>
            <p>
              <bio>
                My research interests lie in 3D computer vision, especially object-level and scene-level perception,
                including camera localization, object pose estimation and zero-shot instance segmentation.
              <bio>

            </p>
          </td>
        </tr>
        </tbody>
      </table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody>
        <tr>
          <td style="padding-bottom: 5px; padding-top: 20px">
            <heading>Publications</heading>
          </td>
        </tr>
        <tr>
          <td style="padding-bottom: 10px; padding-top: 5px; font-size: 14px">
            *: equal contribution; &dagger; corresponding author(s)
          </td>
        </tr>
        </tbody>
      </table>


      <table style="width: 100%; border: 0px; border-spacing: 0px; border-collapse: separate; margin-right: auto; margin-left: auto; ">
        <tbody>


        <tr>
          <td style="padding: 20px; padding-bottom: 30px; width: 30%; vertical-align: middle">
            <img style="width: 100%; max-width: 100%" src='images/sai3d.jpg'>
          </td>
          <td style="padding: 20px; padding-bottom: 30px; width: 70%; vertical-align: middle">
            <papertitle>SAI3D: Segment Any Instance in 3D Scenes</papertitle>
            <br>
            <b>Yingda Yin</b>*,
            Yuzheng Liu*,
            <a href="https://youngxiao13.github.io/">Yang Xiao</a>*,
            <a href="https://danielcohenor.com/">Daniel Cohen-Or</a>,
            <a href="https://cs.stanford.edu/~jingweih/">Jingwei Huang</a>,
            <a href="https://cfcs.pku.edu.cn/baoquan/">Baoquan Chen</a>
            <br>
            <em>CVPR</em> 2024
            <br>
            <a href="https://arxiv.org/abs/2312.11557">arXiv</a> /
            <a href="https://yd-yin.github.io/SAI3D"> project page </a>
<!--            <a href="https://github.com/PKU-EPIC/RotationNormFlow"> code </a> /-->
<!--            <a href="https://youtu.be/0t_GyLGsmV8"> video </a>-->
            <p style="margin-bottom: 10px; margin-top: 10px">
              We introduce a zero-shot 3D instance segmentation approach that synergistically leverages geometric priors and semantic cues derived from Segment Anything Model (SAM).
            </p>
          </td>
        </tr>


        <tr>
          <td style="padding: 20px; padding-bottom: 30px; width: 30%; vertical-align: middle">
            <img style="width: 100%; max-width: 100%" src='images/flow.jpg'>
          </td>
          <td style="padding: 20px; padding-bottom: 30px; width: 70%; vertical-align: middle">
            <papertitle>Delving into Discrete Normalizing Flows on SO(3) Manifold for Probabilistic Rotation Modeling</papertitle>
            <br>
            Yulin Liu*,
            Haoran Liu*,
            <b>Yingda Yin</b>*,
            Yang Wang,
            <a href="https://cfcs.pku.edu.cn/baoquan/">Baoquan Chen</a><sup>&dagger;</sup>,
            <a href="https://hughw19.github.io/">He Wang</a><sup>&dagger;</sup>
            <br>
            <em>CVPR</em> 2023
            <br>
            <a href="https://arxiv.org/abs/2304.03937">arXiv</a> /
            <a href="https://pku-epic.github.io/RotationNormFlow/"> project page </a> /
            <a href="https://github.com/PKU-EPIC/RotationNormFlow"> code </a> /
            <a href="https://youtu.be/0t_GyLGsmV8"> video </a>
            <p style="margin-bottom: 10px; margin-top: 10px">
              We propose a discrete normalizing flow on SO(3) manifold, through which one can not only effectively express arbitrary distributions on SO(3),
              but also conditionally build the target distribution given input observations.
            </p>
          </td>
        </tr>

        <tr>
          <td style="padding: 20px; padding-bottom: 30px; width: 28%; vertical-align: middle">
            <img style="width: 100%; max-width: 100%" src='images/laplace.jpg'>
          </td>
          <td style="padding: 20px; padding-bottom: 30px; width: 72%; vertical-align: middle">
            <papertitle>A Laplace-inspired Distribution on SO(3) for Probabilistic Rotation Estimation</papertitle>
            <br>
            <b>Yingda Yin</b>,
            Yang Wang,
            <a href="https://hughw19.github.io/">He Wang</a><sup>&dagger;</sup>,
            <a href="https://cfcs.pku.edu.cn/baoquan/">Baoquan Chen</a><sup>&dagger;</sup>,
            <br>
            <em>ICLR</em> 2023 &nbsp; <b style="color: red">(Spotlight Presentation, Top 8%)</b>
            <br>
            <a href="https://arxiv.org/abs/2303.01743">arXiv</a> / <a href="https://pku-epic.github.io/RotationLaplace/"> project page </a> /
            <a href="https://github.com/yd-yin/RotationLaplace"> code </a>
<!--            <a href="https://arxiv.org/abs/2203.15765">arXiv</a> / <a href="https://yd-yin.github.io/FisherMatch/"> project page </a> /-->
<!--             / <a href="https://youtu.be/GwQhnG6krCI"> video </a>-->
            <p style="margin-bottom: 10px; margin-top: 10px">
              We propose a novel Rotation Laplace distribution for probabilistic rotation estimation.
              Rotation Laplace distribution is robust to the disturbance of outliers and enforces much gradient to the low-error region,
              resulting in new state-of-the-art performance over both probabilistic and non-probabilistic baselines.
            </p>
          </td>
        </tr>

        <tr>
          <td style="padding: 20px; padding-bottom: 30px; width: 28%; vertical-align: middle">
            <img style="width: 100%; max-width: 100%" src='images/AccurateACL.gif'>
          </td>
          <td style="padding: 20px; padding-bottom: 30px; width: 72%; vertical-align: middle">
            <papertitle>Towards Accurate Active Camera Localization</papertitle>
            <br>
            Qihang Fang&ast;,
            <b>Yingda Yin&ast;</b>,
            <a href="https://fqnchina.github.io/">Qingnan Fan</a><sup>&dagger;</sup>,
            <a href="https://fxia22.github.io/">Fei Xia</a>,
            <a href="https://siyandong.github.io/">Siyan Dong</a>,
            Sheng Wang,<br>
            <a href="https://juewang725.github.io/">Jue Wang</a>,
            <a href="https://geometry.stanford.edu/member/guibas/">Leonidas Guibas</a>,
            <a href="https://cfcs.pku.edu.cn/baoquan/">Baoquan Chen</a><sup>&dagger;</sup>
            <p style="margin: 0; margin-bottom: 2px; font-size: 14px; line-height: 1.4">
            &ast; Equal contribution; ordered alphabetically.
            </p>
            <em>ECCV</em> 2022
            <br>
            <a href="https://arxiv.org/abs/2012.04263"> arXiv </a> / <a href="https://github.com/qhFang/AccurateACL"> code </a> /
            <a href="https://youtu.be/pDMoZ6pjkkQ"> video </a> / <a href="https://yd-yin.github.io/posters/AccurateACL.pdf"> poster </a>
            <p style="margin-bottom: 10px; margin-top: 10px">
              We explicitly model the camera and scene uncertainty components to solve the problem of active camera localization by reinforcement learning.
              Our algorithm improves over the state-of-the-art Markov Localization based approaches by a large margin on the fine-scale camera pose accuracy.
            </p>
          </td>
        </tr>


        <tr>
          <td style="padding: 20px; padding-bottom: 30px; width: 28%; vertical-align: middle">
            <img style="width: 100%; max-width: 100%" src='images/fishermatch1.png'>
          </td>
          <td style="padding: 20px; padding-bottom: 30px; width: 72%; vertical-align: middle">
            <papertitle>FisherMatch: Semi-Supervised Rotation Regression via Entropy-based Filtering</papertitle>
            <br>
            <b>Yingda Yin</b>,
            Yingcheng Cai,
            <a href="https://hughw19.github.io/">He Wang</a><sup>&dagger;</sup>,
            <a href="https://cfcs.pku.edu.cn/baoquan/">Baoquan Chen</a><sup>&dagger;</sup>,
            <br>
            <em>CVPR</em> 2022 &nbsp; <b style="color: red">(Oral Presentation, Top 4%)</b>
            <br>
            <a href="https://arxiv.org/abs/2203.15765">arXiv</a> / <a href="https://yd-yin.github.io/FisherMatch/"> project page </a> /
            <a href="https://github.com/yd-yin/FisherMatch"> code </a> / <a href="https://youtu.be/GwQhnG6krCI"> video </a> /
            <a href="https://yd-yin.github.io/posters/FisherMatch.pdf"> poster </a>
            <p style="margin-bottom: 10px; margin-top: 10px">
              We propose the first general framework for semi-supervised rotation regression. <br>
              Our algorithm models the uncertainty of rotation regression with the help of probabilistic modeling of SO(3),
              which facilitates the pseudo-label filtering in semi-supervised learning.
            </p>
          </td>
        </tr>


        <tr>
          <td style="padding: 20px; padding-bottom: 30px; width: 28%; vertical-align: middle">
            <img style="width: 100%; max-width: 100%" src='images/rpmg.jpg'>
          </td>
          <td style="padding: 20px; padding-bottom: 30px; width: 72%; vertical-align: middle">
            <papertitle>Projective Manifold Gradient Layer for Deep Rotation Regression</papertitle>
            <br>
            <a href="https://jychen18.github.io/"> Jiayi Chen</a>,
            <b>Yingda Yin</b>,
            <a href="http://ww1.tbirdal.me/">Tolga Birdal</a>,
            <a href="https://cfcs.pku.edu.cn/baoquan/">Baoquan Chen</a>,
            <a href="https://geometry.stanford.edu/member/guibas/">Leonidas Guibas</a>,
            <a href="https://hughw19.github.io/">He Wang</a><sup>&dagger;</sup>
            <br>
            <em>CVPR</em> 2022
            <br>
            <a href="https://arxiv.org/abs/2110.11657"> arXiv </a> / <a href="https://jychen18.github.io/RPMG/"> project page</a> /
            <a href="https://github.com/jychen18/RPMG"> code </a> / <a href="https://youtu.be/cb1T8dnHQdQ"> video </a> /
            <a href="https://yd-yin.github.io/posters/RPMG.pdf"> poster </a>
            <p style="margin-bottom: 10px; margin-top: 10px">
              We focus on improving the backward pass of deep rotation regression. Leveraging Riemannian optimization,
              we propose a SO(3) manifold-aware gradient that directly backpropagates into deep network weights.
              Our plug-and-play gradient layer can be applied to different rotation representations.
            </p>
          </td>
        </tr>


        <tr>
          <td style="padding: 20px; padding-bottom: 30px; width: 28%; vertical-align: middle">
            <img style="width: 100%; max-width: 100%" src='images/reflection.jpg'>
          </td>
          <td style="padding: 20px; padding-bottom: 30px; width: 72%; vertical-align: middle">
            <papertitle>Deep Reflection Prior</papertitle>
            <br>
            <b>Yingda Yin&ast;</b>,
            <a href="https://fqnchina.github.io/">Qingnan Fan</a>*,
            <a href="https://www.dongdongchen.bid/">Dongdong Chen</a>,
            Yujie Wang,
            <a href="https://angelicaiaviles.wordpress.com/">Angelica Aviles-Rivero</a>,
            <a href="https://liruoteng.github.io/">Ruoteng Li</a>,
            <a href="https://www.damtp.cam.ac.uk/user/cbs31/Home.html">Carola-Bibiane Schönlieb</a>
            <a href="https://www.cs.huji.ac.il/~danix/">Dani Lischinski</a>,
            <a href="https://cfcs.pku.edu.cn/baoquan/">Baoquan Chen</a>
            <br>
            <em>ArXiv</em> 2019
            <br>
            <a href="https://arxiv.org/abs/1912.03623"> arXiv </a>
            <p style="margin-bottom: 10px; margin-top: 10px">
              We propose a learning-based approach that captures the reflection statistical prior for single image reflection removal.
              Our algorithm is driven by optimizing the target with joint constraints enhanced between multiple input images during the training stage,
              but is able to eliminate reflections only from a single input for evaluation.
            </p>
          </td>
        </tr>



        </tbody>
      </table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody>
        <tr>
          <td style="padding-bottom: 20px; padding-top: 30px">
            <heading>Experience</heading>
          </td>
        </tr>
        </tbody>
      </table>


      <table width="100%" align="center" border="0">
        <tbody>
        <tr>
          <td style="padding: 0px; padding-left: 55px; padding-right: 55px; width: 25%; vertical-align: middle">
            <img style="width: 100%; max-width: 100%" src="images/pku_logo.jpg"></td>
          <td style="padding: 20px; padding-top: 15px; padding-bottom: 15px" width="75%" vertical-align=middle>
            <papertitle>Peking University</papertitle>
            <br>
            Ph.D. student in Computer Applied Technology
            <br>
            Advisor: <a href="https://cfcs.pku.edu.cn/baoquan/">Prof. Baoquan Chen</a>
            <p style="margin-bottom: 0">2019.9 - Present</p>
          </td>
        </tr>

        <tr>
          <td style="padding: 0px; padding-left: 55px; padding-right: 55px; width: 25%; vertical-align: middle">
            <img style="width: 100%; max-width: 100%" src="images/bfa_logo.jpg"></td>
          <td style="padding: 20px; padding-top: 15px; padding-bottom: 15px" width="75%" vertical-align=middle>
            <papertitle>Beijing Film Academy</papertitle>
            <br>
            Research intern at <a href="https://fve.bfa.edu.cn/">Advanced Innovation Center for Future Visual Entertainment</a>
            <br>
            Advisor: <a href="https://cfcs.pku.edu.cn/baoquan/">Prof. Baoquan Chen</a>
            <p style="margin-bottom: 0">2018.12 - 2021.6</p>
          </td>
        </tr>

        <tr>
          <td style="padding: 0px; padding-left: 55px; padding-right: 55px; width: 25%; vertical-align: middle">
            <img style="width: 100%; max-width: 100%" src="images/dlut_logo.jpg">
          </td>
          <td style="padding: 20px; padding-top: 15px; padding-bottom: 15px" width="75%" vertical-align=middle>
            <papertitle>Dalian University of Technology</papertitle>
            <br>
            B.E. in Information and Communication Engineering, Innovation Class<br>
            2015.9 - 2019.7

            <p style="margin-bottom: 0">Grades: 95.40 &nbsp; (Rank 1/197)<br>
            2016 & 2017 & 2018 China National Scholarships</p>
          </td>
        </tr>
        </tbody>
      </table>


      <table style="width: 100%; border: 0px; border-spacing: 0px; border-collapse: separate; margin-right: auto; margin-left: auto; ">
        <tbody>
        <tr>
          <td style="padding: 0px; padding-top: 0px">
            <br>
            <p style="text-align: right; font-size: x-small; ">
              Website template courtesy of <a style="font-size: x-small" href="https://jonbarron.info/">Jon Barron</a>.
            </p>
          </td>
        </tr>
        </tbody>
      </table>
    </td>
  </tr>
</table>
</body>

</html>
